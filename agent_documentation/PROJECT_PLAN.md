## Sâ€‘4â€¯Â Â Replace Example Wrapper with Firstâ€‘Class JNI Binding Â ğŸš§

> **Owner:** â€œJNIâ€‘Bindingâ€â€¯AI agent  
> **Status:** _Planned_  
> **Target branch:** `feature/jni-binding-llama`  
> **Due:** 2025â€‘08â€‘05

### ğŸ¯Â Goal  
Eliminate the 64â€‘token limitation and unlock full llama.cpp capabilities by **dropping `examples/llama.android`** and building our own JNI bridge + Kotlin facade.

### ğŸ”¨Â Deliverables  
| # | Artifact | Location |
|---|----------|----------|
| 1 | **`:llama-binding` library module** (Gradle, Android library) | `/llama-binding` |
| 2 | **CMakeLists.txt** compiling llama.cpp as `libllama-jni.so` | `/llama-binding/src/main/cpp` |
| 3 | **`LlamaJni.cpp`** â€“ minimal C++ wrapper exposing \<10 methods | same |
| 4 | **`Llama.kt`** Kotlin singleton with a `generate()` Flow that accepts `maxTokens` | `/llama-binding/src/main/kotlin` |
| 5 | Updated **settings.gradle.kts** (remove old `:llama` include, add new module) | root |
| 6 | Updated **`LlamaCppInferenceEngine`** pointing to the new API | `app/â€¦/inference` |
| 7 | Instrumentation test that streams â‰¥â€¯256 tokens without truncation | `/llama-binding/src/androidTest` |

### ğŸ”Â Acceptance criteria  
- Loading a 2â€¯Bâ€‘parameter GGUF on Pixel 8 succeeds.  
- `generate(prompt, maxTokens = 256)` returns a Flow that emits â‰¥â€¯256 nonâ€‘empty pieces before EOS.  
- Memory usage measured via `meminfo` is â‰¤â€¯+5â€¯% compared to the old wrapper.  
- ProGuard/R8 keeps JNI symbols (`-keep class com.localassistant.llama.* { *; }`).  
- No code remains under `llama_cpp/examples/llama.android/**/*.kt`.

---

### ğŸ› ï¸Â Detailed task list  

| ID | Task | Description |
|----|------|-------------|
| **Sâ€‘4â€‘1** | **Module bootstrap** | `./gradlew :llama-binding:create` â†’ apply `com.android.library` + `kotlin-android`. |
| **Sâ€‘4â€‘2** | **Copy build flags** | Port NEON/FP16 flags from upstream `CMakeLists.txt` to the new one. |
| **Sâ€‘4â€‘3** | **Add llama subdir** | In CMake: `add_subdirectory(${PROJECT_SOURCE_DIR}/../../llama_cpp libllama EXCLUDE_FROM_ALL)`; link static lib. |
| **Sâ€‘4â€‘4** | **Write `LlamaJni.cpp`** | Expose: `newContext(path)`, `freeContext(ctx)`, `evalTokens(ctx, ids)`, `sample(ctx)`, `tokenEOS(ctx)` (â‰ˆ150â€¯LOC). |
| **Sâ€‘4â€‘5** | **Kotlin facade** | Singleton that loads `System.loadLibrary("llama-jni")`, owns a background dispatcher, and implements `generate(prompt, maxTokens) : Flow<String>`. |
| **Sâ€‘4â€‘6** | **Engine refactor** | Replace `LLamaAndroid.instance()` calls with the new `Llama` object; add EOS stop condition. |
| **Sâ€‘4â€‘7** | **Gradle cleanup** | Remove `include(":llama")` from settings; delete obsolete `projectDir` line. |
| **Sâ€‘4â€‘8** | **ProGuard/R8 rules** | Keep native classes & fields; disable method inlining for `native` functions. |
| **Sâ€‘4â€‘9** | **Instrumentation test** | UI test sends â€œWrite a 300â€‘word storyâ€ and asserts â‰¥â€¯300 words received. |
| **Sâ€‘4â€‘10** | **Docs & sample** | Update README + Architecture docs with new binding diagram. |

---

### â±ï¸Â Effort & sequencing  

1. **Dayâ€¯1** â€“ tasksâ€¯4â€‘1Â toÂ 4â€‘4  
2. **Dayâ€¯2** â€“ tasksâ€¯4â€‘5Â &Â 4â€‘6  
3. **Dayâ€¯3** â€“ tasksâ€¯4â€‘7Â toÂ 4â€‘9, code review  
4. **Dayâ€¯4** â€“ docs, merge

---

### ğŸ““Â Notes & tips  

* The C API (`llama.h`) is now stable; prefer it over C++ helpers.  
* Keep the JNI surface *tiny*: pass byteâ€‘arrays of token IDs instead of strings when feeding prompts.  
* You can copy the logâ€‘toâ€‘Android trick from the example (`llama_log_set()` â†’ `__android_log_print`).  
* Use `gradle.properties`: `android.experimental.disableDuplicateClassCheck=true` while transitioning modules.  
* Remember to increment `versionCode` after ABI change.

---

### ğŸ”—Â References  

* Upstream discussion on `nlen` issue: ggerganov/llama.cppâ€¯#6108  
* Internal design doc: `agent_documentation/deep_dives/LLAMA_CPP.md` (section â€œBuild & Integration Processâ€)  
* Android NDK r27 â€“Â CMake toolchain defaults.
